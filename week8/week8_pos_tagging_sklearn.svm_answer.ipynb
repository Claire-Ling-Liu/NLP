{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# SVM for POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will implement a POS tagging system by using the SVM classifier, sweeping left-to-right, and classifying each word into classes of different parts-of-speech. We will use the scikit-learn library.\n",
    "\n",
    "**training data**: wsj00-18.tag\n",
    "\n",
    "**testing data**: wsj22-24.tag\n",
    "\n",
    "Please **output** a file pos.guessa that is identical to wsj22-24.tag, except it adds a new field last which is the result of your classifier.\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "The focus of the task is on feature engineering. The following features are good to start with:\n",
    "\n",
    "- word form\n",
    "- suffix\n",
    "- whether it is a digit or not\n",
    "- initial letter capitalized or not\n",
    "- word on left\n",
    "- word on right\n",
    "- previous tag\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readconll(file):\n",
    "    lines = [line.strip() for line in open(file)]\n",
    "    while lines[-1] == '':  # Remove trailing empty lines\n",
    "        lines.pop()\n",
    "    s = [x.split('_') for x in '_'.join(lines).split('__')]  # Quick split corpus into sentences\n",
    "    return [[y.split() for y in x] for x in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = readconll('wsj00-18.tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FeatureExtract(word, history, future):\n",
    "    \n",
    "    #current word in lower case, previous word, previous tag, next word\n",
    "    feature_dict = {word.lower():1, history[-1][0]:1, history[-1][1]:1, future[0]:1}\n",
    "    \n",
    "    #first letter capitalized or not\n",
    "    if w[0].isupper():\n",
    "        feature_dict['Upper1'] = 1\n",
    "        \n",
    "    #Suffixes\n",
    "    for i in range(1, len(word)):\n",
    "        feature_dict['suf-'+word[-i:]] = 1\n",
    "        \n",
    "    if w.isdigit():\n",
    "        feature_dict['isdigit'] = 1\n",
    "        \n",
    "    return feature_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer(sparse=True)\n",
    "clf = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training \n",
    "\n",
    "features = []\n",
    "classes = []\n",
    "for sentence in sentences:\n",
    "    for i, (w, c) in enumerate(sentence):\n",
    "        if i == 0:\n",
    "            history = [['<s>', '<S>']]\n",
    "        else:\n",
    "            history = sentence[:i]\n",
    "        if i == len(sentence) -1:\n",
    "            future = ['</s>']\n",
    "        else:\n",
    "            future = [word for word, tag in sentence][i+1:]\n",
    "        classes.append(c)\n",
    "        features.append(FeatureExtract(w, history, future))\n",
    "        \n",
    "X = vectorizer.fit_transform(features)\n",
    "clf.fit(X, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words correctly tagged:  125052.0\n",
      "Number of all words tagged:  129654.0\n",
      "Accuracy:  96.4506\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "fw = open('pos.guess', 'w')\n",
    "test_sentences = readconll('wsj22-24.tag')\n",
    "\n",
    "gc = 0.0\n",
    "cc = 0.0\n",
    "for sentence in test_sentences:\n",
    "    testdata = [word for word, tag in sentence]\n",
    "    guesstags = []\n",
    "    for i, w in enumerate(testdata):\n",
    "        if i == 0:\n",
    "            history = [('<s>', '<S>')]\n",
    "        else:\n",
    "            history = list(zip(testdata[:i], guesstags))\n",
    "            #print (history)\n",
    "        if i == len(testdata) -1:\n",
    "            future = ['</s>']\n",
    "        else:\n",
    "            future = testdata[i+1:]\n",
    "        test_features = vectorizer.transform([FeatureExtract(w, history, future)])\n",
    "        guesstag = clf.predict(test_features)[0]\n",
    "        guesstags.append(guesstag) \n",
    "    \n",
    "    \n",
    "    for (w, t), g in zip(sentence, guesstags):\n",
    "        if t == g:\n",
    "            cc += 1\n",
    "        gc += 1\n",
    "        fw.write(w+'\\t'+t+'\\t'+g+'\\n')\n",
    "    fw.write('\\n') \n",
    "fw.close()\n",
    "\n",
    "print (\"Number of words correctly tagged: \", cc)\n",
    "print (\"Number of all words tagged: \", gc)\n",
    "print (\"Accuracy: \", round(cc*100/gc, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
